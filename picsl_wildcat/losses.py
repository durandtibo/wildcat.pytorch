import torch
import torch.nn as nn
import torchvision.models as models
import torch.nn.functional as F

class SegmentationContrastiveLoss(nn.Module):
    """
    This loss check to what extent the segmentation of an image generated by
    a u-net like model clusters input image intensities or pixel-level features.
    Given an [B,C,W,H] feature image with C channels and a [B,K,W,H] image of
    class membership probabilities [0-1 range] with K classes, it computes the
    weighted means for each of the K classes and the weighted squared distance
    to each cluster mean. The loss is then based on the ratio of the within-class
    distances to the means and between-class distances to the mean. Basically, the
    more clustered the features for each class are, the better. Clustering is done
    separately for each member of the mini-batch, there is no assumption that the
    same class in different images will have the same features.
    """
    
    def __init__(self, tau=1.0):
        super(SegmentationContrastiveLoss, self).__init__()
        self.tau = tau

    def forward(self, feats, probs):
        # Compute the cluster means
        c_means = torch.einsum('bkij,bcij->bkc',probs,feats) / torch.einsum('bkij->bk',probs).unsqueeze(-1)

        # Squared deviations from the means at each pixel
        c_sqdev = torch.sum((feats.unsqueeze(1) - c_means.unsqueeze(-1).unsqueeze(-1))**2, axis=2)

        # Average cluster-to-center squared distance matrix (entry b,p,k is the average distance
        # from cluster p to center k)
        c_dmat = torch.einsum('bkij,bpij->bkp',probs,c_sqdev) / torch.einsum('bkij->bk',probs).unsqueeze(-1)

        # Matrix of penalties
        c_exp_dmat_diag = torch.exp(torch.diagonal(c_dmat,dim1=1,dim2=2) / self.tau)
        c_pmat = -torch.log(c_exp_dmat_diag / (torch.sum(torch.exp(c_dmat  / self.tau),axis=1) - c_exp_dmat_diag))

        # Return the average penalty for each input (adding across classes)
        return torch.mean(c_pmat, axis=1)


class TanglethonLoss(nn.Module):
    """
    This loss takes into account that some patches in the weakly supervised histology
    database may contain multiple classes; for example, the patch labeled tangle may
    also contain instances of threads and background objects. The loss does not penalize
    patches labeled as 'tangle' from containing thread and background activations.
    """
    
    def __init__(self, weights: torch.Tensor):
        """
        weights: A square matrix with dimensions [k,k] where k is the number of classes. The
        element in row i and column j specifies that if the true label of a patch is i and the
        assigned label is j, then the loss should be incremented by w(i,j). For example if the
        classes are 0: background, 1: thread, 2: tangle, 3: other, and the following matrix is
        specified:

        [ 0   1/3 1/3 1/3
          0   0   1/2 1/2
          0   0   0   1
          0   0   1   0   ]

        It means that if a patch is truly background, then assigning it any other label carries 
        the penalty of 1/3; if a patch is truly thread, then assigning it label of background or
        thread is ok (no penalty) but assigning it the label of tangle or other is penalized 1/2.
        """
        super(TanglethonLoss, self).__init__()
        self.w = torch.nn.Parameter(weights, requires_grad=False)
        
    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        """
        Compute the loss for a mini-batch

        input: [B,K] tensor of activations, for K classes. The activations will be passed through
        a sigmoid filter to map them to the 0 to 1 range. You should not pass the input through a
        softmax filter, since that makes the labels compete against each other and this loss 
        allows multiple classes to have strong activations.

        target: [B,K] tensor, one-hot-vector

        returns: loss value
        """
        # Map the activations to probabilities
        prob = torch.sigmoid(input)
        
        # Compute the first part of the loss, y_i log(p_i)
        alpha = torch.einsum('bk,bk->b', target, -torch.clamp(torch.log(prob),min=-20))
        
        # Compute the second part of the loss, (1-y_i) log(1-p_i)
        beta = torch.einsum('bk,kl,bl->b', target, self.w, -torch.clamp(torch.log(1-prob), min=-20))
        
        # Result
        res = torch.mean(alpha + beta)
        if torch.isnan(res) or torch.isinf(res):
            print('NONNUMERIC RESULT')
            print(input, target, alpha, beta)
        
        # Return the average loss for this minimatch
        return res
    
    def predictions(self, input: torch.Tensor) -> torch.Tensor:
        """
        Compute predictions for a mini-batch

        input: [B,K] tensor of activations, for K classes. Same as for forward(). 

        returns: a vector of predictions, i.e., class for which the loss value is lowest. 
        """
        # Create an identity matrix for testing 
        idmat = torch.diag(torch.ones_like(torch.diag(self.w)))
        
        # Map the activations to probabilities
        prob = torch.sigmoid(input)
        
        # Compute the first part of the loss, y_i log(p_i)
        alpha = torch.einsum('mk,bk->bm', idmat, -torch.clamp(torch.log(prob),min=-20))
        
        # Compute the second part of the loss, (1-y_i) log(1-p_i)
        beta = torch.einsum('mk,kl,bl->bm', idmat, self.w, -torch.clamp(torch.log(1-prob), min=-20))
        
        # Get the predictions
        _,pred = torch.min(alpha+beta, 1)
        
        return pred
    

class MultiLabelSoftMarginLoss(nn.MultiLabelSoftMarginLoss):
    """
    A wrapper around nn.MultiLabelSoftMarginLoss that supports a common interface we are using
    """
    def __init__(self):
        super(MultiLabelSoftMarginLoss, self).__init__()

    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
        return super(MultiLabelSoftMarginLoss, self).forward(input, target)
    
    def predictions(self, input: torch.Tensor) -> torch.Tensor:
        _, preds = torch.max(input, 1)
        return preds
